version: v1beta
variable:
  document_input:
    title: Document Input
    description: Upload a document (PDF/DOCX/DOC/PPTX/PPT)
    type: file
  pipeline_url:
    title: Pipeline URL
    description: pipeline-backend's (internal) public API URL
    type: string
  model_url:
    title: Model URL
    description: model-backend's (internal) public API URL
    type: string
  user_uid:
    title: User UID
    description: The UID of the authenticated user.
    type: string
  requester_uid:
    title: Requester UID
    description: The UID of the namespace requesting the trigger.
    type: string
component:
  pages-to-images:
    type: document
    task: TASK_CONVERT_TO_IMAGES
    input:
      document: ${variable.document_input}
      resolution: 300
  batch-images:
    type: collection
    input:
      data: ${pages-to-images.output.images}
      size: 2
    task: TASK_SPLIT
  router:
    type: openai
    task: TASK_TEXT_GENERATION
    input:
      model: gpt-4o-mini
      images: ${batch-images.output.data[0]}
      n: 1
      prompt: |-
        Here are images of a document.
        Based on the layout, visual complexity, and presence of text, tables, or visual elements, classify the document into one of the following processing categories:

        1. Standard Document Operator
        2. Docling Model
        3. Visual Language Model Pipeline
      response-format:
        json-schema: |
          {
              "name": "document_classification_evaluation",
              "strict": true,
              "schema": {
                  "type": "object",
                  "properties": {
                      "selectedCategory": {
                          "type": "string",
                          "enum": ["Standard Document Operator", "Docling Model", "Visual Language Model Pipeline"],
                          "description": "The model's chosen document classification"
                      }
                  },
                  "required": ["selectedCategory"],
                  "additionalProperties": false
              }
          }
        type: json_schema
      system-message: |-
        You are an expert document analysis assistant. Your task is to examine images of documents and classify each into one of three categories for processing:

        1. **Standard Document Operator** - Use this for plain documents with simple text formatting and minimal structure. No images or complex tables.
        2. **Docling Model** - Choose this for documents with complex formatting, numerous structured tables, or nested layouts. Great for financial reports or regulatory documents.
        3. **Visual Language Model Pipeline** - Select this if the document relies heavily on visual elements such as charts, graphs, diagrams, photographs, or illustrated content.

        Your decision should be based solely on the **visual characteristics** of the document as seen in the provided images. Do not analyze the document's content or meaning beyond its layout and presentation.
      temperature: 0
      top-p: 0.01
  string-to-json:
    type: json
    input:
      string: ${router.output.texts[0]}
    task: TASK_UNMARSHAL
  heuristic:
    type: document
    task: TASK_CONVERT_TO_MARKDOWN
    input:
      document: ${variable.document_input}
      display-image-tag: false
      display-all-page-image: false
      resolution: 300
      converter: pdfplumber
    condition: ${string-to-json.output.json.selectedCategory} != "Docling Model"
  get-encoded-images:
    type: iterator
    input: ${pages-to-images.output.images}
    output-elements:
      result: ${get-encoded-images.element:data-uri}
    condition: ${string-to-json.output.json.selectedCategory} != "Docling Model"
  vlm-refinement:
    type: http
    task: TASK_POST
    input:
      endpoint-url: ${variable.pipeline_url}/v1beta/namespaces/preset/pipelines/vlm-refinement/releases/v1.0.0/trigger
      header:
        Instill-User-Uid:
          - ${variable.user_uid}
        Instill-Requester-Uid:
          - ${variable.requester_uid}
        Instill-Auth-Type:
          - user
      body:
        data:
          - variable:
              document-page-images: ${get-encoded-images.output.result}
              document-page-markdowns: ${heuristic.output.markdowns}
    condition: ${string-to-json.output.json.selectedCategory} == "Visual Language Model Pipeline" && ${heuristic.output.body} != ""
    setup:
      authentication:
        auth-type: NO_AUTH
  vlm-ocr:
    type: http
    task: TASK_POST
    input:
      endpoint-url: ${variable.pipeline_url}/v1beta/namespaces/preset/pipelines/vlm-ocr/releases/v1.0.0/trigger
      header:
        Instill-User-Uid:
          - ${variable.user_uid}
        Instill-Requester-Uid:
          - ${variable.requester_uid}
        Instill-Auth-Type:
          - user
      body:
        data:
          - variable:
              document-page-images: ${get-encoded-images.output.result}
    condition: ${string-to-json.output.json.selectedCategory} == "Visual Language Model Pipeline" && ${heuristic.output.body} == ""
    setup:
      authentication:
        auth-type: NO_AUTH
  docling:
    type: http
    task: TASK_POST
    input:
      endpoint-url: ${variable.model_url}/v1alpha/namespaces/instill-ai/models/docling/versions/v0.1.0/trigger
      header:
        Instill-User-Uid:
          - ${variable.user_uid}
        Instill-Requester-Uid:
          - ${variable.requester_uid}
        Instill-Auth-Type:
          - user
      body: |-
        {
            "taskInputs": [
                {
                    "data": {
                        "doc_content": "${variable.document_input:data-uri}"
                    }
                }
            ]
        }
    condition: ${string-to-json.output.json.selectedCategory} == "Docling Model"
    setup:
      authentication:
        auth-type: NO_AUTH
output:
  parsing-strategy:
    title: Parsing Strategy
    value: ${string-to-json.output.json.selectedCategory}
  heuristic:
    title: Standard Document Operator
    value: ${heuristic.output.markdowns}
  docling:
    title: Docling
    value: ${docling.output.body.taskOutputs[0].data}
  vlm-ocr:
    title: VLM OCR
    value: ${vlm-ocr.output.body.outputs[0].converted-markdown}
  vlm-refinement:
    title: VLM Refinement
    value: ${vlm-refinement.output.body.outputs[0].converted-markdown}
